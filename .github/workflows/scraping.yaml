name: "Knowledge Scraping - blogs" 
on:
  workflow_dispatch:
  schedule:
    - cron: '0 0 * * *'  # Runs daily at midnight UTC 
jobs:
  scrape-blogs:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.x'  
      - name: Install Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests beautifulsoup4
      - name: Run Your Script
        run: |
          echo "Running the scraping task"
          python scripts/addknowledge_blog.py  
      - name: Commit and push if content changed
        env:
          REPO_ACCESS_TOKEN: ${{ secrets.REPO_ACCESS_TOKEN }}
        run: |-
          git config user.name "Automated"
          git config user.email "actions@users.noreply.github.com"
          git add -A
          timestamp=$(date -u)
          git commit -m "Latest data: ${timestamp}" || exit 0
          git push https://x-access-token:${REPO_ACCESS_TOKEN}@github.com/0xLazAI/alith.git HEAD:main